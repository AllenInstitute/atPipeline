#
# Docker file to build entire AT pipeline software stack into a single container
# Based on
#   https://raw.githubusercontent.com/fcollman/render-deploy/base-image/shared/Dockerfile
#
# TODO: Seperate builders for artifacts
# TODO: Set up continuous integration
#

FROM continuumio/miniconda:4.5.12
RUN conda update conda && conda update python && conda install nomkl
#install java
RUN set -ex && \
    echo 'deb http://deb.debian.org/debian stretch-backports main' \
      > /etc/apt/sources.list.d/stretch-backports.list && \
    apt-get update -y && \
    apt-get install -t \
      stretch-backports \
      openjdk-8-jdk \
      ca-certificates-java -y &&\
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /shared
WORKDIR /shared
RUN apt-get update && \
    apt-get install --no-install-recommends gcc build-essential libgeos-dev imagemagick xvfb vim maven -y  

# add a simple script that can auto-detect the appropriate JAVA_HOME value
# based on whether the JDK or only the JRE is installed
RUN { \
		echo '#!/bin/sh'; \
		echo 'set -e'; \
		echo; \
		echo 'dirname "$(dirname "$(readlink -f "$(which javac || which java)")")"'; \
	} > /usr/local/bin/docker-java-home \
	&& chmod +x /usr/local/bin/docker-java-home

# do some fancy footwork to create a JAVA_HOME that's cross-architecture-safe
RUN ln -svT "/usr/lib/jvm/java-8-openjdk-$(dpkg --print-architecture)" /docker-java-home

# Spark setup
ENV SPARK_VERSION 2.0.2
ENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-hadoop2.7
ENV SPARK_HOME /usr/spark-${SPARK_VERSION}
ENV SPARK_DIST_CLASSPATH="$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share"
ENV PATH $PATH:${SPARK_HOME}/bin
RUN curl -sL --retry 3 \
"https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop2.7.tgz" \
 | gunzip \
 | tar x -C /usr/ \
&& mv /usr/$SPARK_PACKAGE $SPARK_HOME \
&& chown -R root:root $SPARK_HOME

# Build the render client scripts
ENV JAVA_HOME /docker-java-home
ENV RENDER_JAVA_HOME /docker-java-home
ENV RENDER_CLIENT_SCRIPTS=/shared/render/render-ws-java-client/src/main/scripts

# Work around OpenJDK bug with surefire plugin for both render and at_modules
ENV _JAVA_OPTIONS -Djdk.net.URLClassPath.disableClassPathURLCheck=true

# Install Render
WORKDIR /shared/render/
RUN git clone --branch at_develop --single-branch https://github.com/perlman/render.git /shared/render
RUN mvn clean && mvn -T 1C -Dproject.build.sourceEncoding=UTF-8 package

# Install at_modules
WORKDIR /shared/at_modules
COPY ./at_modules/ /shared/at_modules
RUN mvn install

# Install EM_Aligner from github (we need >= 0.3.5 for multiple match collections)
RUN pip install git+https://github.com/AllenInstitute/EM_aligner_python

# Install render-python
WORKDIR /shared/render-python
RUN git clone --branch master --single-branch https://github.com/fcollman/render-python.git /shared/render-python
RUN pip install -e /shared/render-python

# Install render-modules
WORKDIR /shared/render-modules
RUN git clone --branch at_develop --single-branch https://github.com/AllenInstitute/render-modules.git /shared/render-modules
RUN pip install -e /shared/render-modules

# Install render-python-apps
RUN apt-get install libspatialindex-dev -y
WORKDIR /shared/render-python-apps
RUN git clone --branch at_develop --single-branch https://github.com/AllenInstitute/render-python-apps.git /shared/render-python-apps
RUN pip install -e /shared/render-python-apps

WORKDIR /work

# Clean stuff up
RUN apt-get remove --purge gcc build-essential libgeos-dev -y && apt-get autoremove -y &&\
    rm -rf /var/lib/apt/lists/*

ENTRYPOINT [ "/usr/bin/tini", "--" ]
CMD [ "/bin/bash" ]
